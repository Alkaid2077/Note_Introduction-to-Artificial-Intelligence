# 人工智能导论_复旦大学_智慧慕课学习空间

## 绪章

### 课程导引

#### 1. **人工智能：科学的思考方式**

- 像人一样思考 -> 理性地思考
- 像人一样行动 -> 理性地行动
- ->理性的决策

  - 理性的决策：可以最优地达成预先定义目标的决策
  - “理性”的评价仅仅基于决策（并不在意背后的思考过程）
  - 目标：基于执行结果的效用进行刻画
  - 理性；最大化期望的效用值 

#### 2. **课程目标**

- 智能体：一个可以完成*感知*和*动作*的实体。
- 理性的智能体：选择最大化期望效用的动作。
- 核心要素：反馈，环境和动作空间。
- 基于三大核心要素进行动作选择。
- 课程内容：
  - 学习针对一系列问题类型的通用人工智能技术
  - 学习如何使用现有技术进行新问题的建模和求解

#### 3. 人工智能技术学习路径

- 基础_真实世界的问题：路径寻址，吃豆人，五子棋，……
- 抽象_形式化任务（模型）：搜索问题，马尔可夫决策过程，贝叶斯问题，……
- 计算_任务的解决（算法）：深度优先，策略优先，维特比算法

## 一、无信息搜索

### 1.1 搜索问题定义

#### 1.1.1 搜索问题四要素

- **状态/状态空间**
  - 状态描述一个具体的场景
  - 状态空间包含了所有的可能状态
- **后继函数（动作、损耗）**
  - 状态通过动作选择而产生连接的关系
  - 动作空间表示某一个状态下可以采取的动作集合
- **开始状态**
  - 问题开始的状态
- **结束状态**
  - 问题结束的条件

#### 1.1.2 吃豆人游戏

>背景：小黄人吃豆子，小豆子+大豆子，有敌人，小黄人碰到敌人gg，吃到大豆子可以变大吃敌人

- 状态空间：游戏过程中的某个画面的截图，每一个小格子都是一个状态的可能，所有的格子的状态组成了状态空间
- 后继函数
  - 动作空间：上，下，左，右，动作可以连接两个状态
  - 损耗：每个动作都有损耗，单步损耗为1
  - 如小黄人从（1，1）移动到（1，2），向右移动一格，（1，2）里有豆子，小黄人就吃到了豆子，这个向右一格的动作连接了两个状态
- 开始状态：如小黄人从（1，1）的状态开始，其他格子里有豆子
- 目标测试：如移动到某一个特定的位置/吃完所有豆子

#### 1.1.3 八数码问题

>在 3x3 的格子中有 1~8 八个数字，你可以移动一个数码到它旁边的空格子中，从开始状态达到目标状态
>![alt text](image-1.png)

- 状态空间：8 个数码的位置，每一个都可以用二维数组表示（x, y）
- 后继函数：移动空白格子：上，下，左，右

#### 1.1.4 八皇后问题

> 在 8x8 的棋盘上，陆续摆上 8 个皇后，并保证皇后之间两两不互相攻击（皇后可以攻击同一行、同一列、同一正对角线/反对角线的棋子），在图示例子中，我们还需要摆放 3 个皇后 
> ![alt text](image-2.png)

- 状态空间：0 ~ 8 个皇后摆在棋盘上；使用一个 8x8 的矩阵，布尔值
- 后继函数：增加一个皇后到棋盘上
- 开始状态：空白的棋盘
- 目标测试：8 个皇后在棋盘上，两两不攻击

#### 1.1.5 罗马尼亚交通图

> ![alt text](image-3.png)

- 状态空间：图中的节点集（城市是节点）
- 后继函数：动作-可以去往有边相连的城市；损耗-城市间的距离
- 开始状态：Arad （城市）
- 目标检测：当前所处的城市是否是 Bucharest？

### 1.2 搜索空间

#### 1.2.1 状态空间

- **全局状态空间**：建模没环境中包含的每一个可描述变量（细节），如包括小黄人的位置，豆子分布情况，大豆子小豆子，敌人等等
- **搜索状态空间**：仅需要建模解决特定搜索问题需要的变量，不需要所有的变量
  - 问题：路径寻址
    - 状态：（x, y）小黄人的位置
    - 动作：上下左右
    - 后继：根据动作更新位置
    - 目标：当前状态是否目标位置
  - 问题：吃完所有豆子
    - 状态：{（x,y），豆子分布情况}
    - 动作：上下左右
    - 后继：根据动作状态
    - 目标：所有豆子都被吃了

#### 1.2.2 状态空间的大小 - 八皇后问题

- 全局状态空间：期盼的格子数目 64，皇后的数目 8
- 全局状态空间大小：$64^8$

#### 1.2.3 状态空间的大小 - 吃豆人

- 全局状态空间：小黄人活动空间 120，豆子个数 30，鬼怪活动空间 12，小黄人朝向 上下左右
- 全局状态空间大小：$120*(2^{30})*(12^2)*4$
- 路径搜索状态空间大小：$120$
- 吃完所有豆子状态空间：$120*(2^{30})$

### 1.3 搜索问题的表示：状态空间图和搜索树

#### 1.3.1 状态空间图

- 定义：一种针对搜索问题的数学表示形式
  - 节点：抽象的状态
  - 边：后继函数（状态执行动作的结果）
  - 目标检测：一个目标节点的集合（可能只有一个）
- 在状态空间图中，每一个问题中的状态只出现一次
- 状态空间图中的节点与问题中的状态一一对应

#### 1.3.2 搜索树

- 树是有向无环图，有根节点，边的个数是节点个数减一
  - 开始状态是根节点
  - 子节点对应父节点的后继状态
  - 节点对应状态，并且包含了从开始状态到当前状态的路径，
  - **路径表示一个动作序列**

#### 1.3.3 状态空间图到搜索树的转换

![alt text](image-4.png)

- 搜索树中的一个节点对应状态空间图中的一条完整路径
- 状态空间图中的节点可以对应到搜索树中的多个状态节点，也就是说，**搜索树中不同的节点可能表示相同的状态，只是路径不同**

#### 1.3.4 状态空间图 vs. 搜索树

考虑以下 4 状态的状态空间图，它对应的搜索树是怎么样的？
![alt text](image-5.png)

此图中 a,b 一直在循环。在搜索树中包含了非常多的重复结构，因此，对于绝大部分问题来说，我们不能完整画出它对应的搜索树。

### 1.4 搜索算法的基本设定和评测

#### 1.4.1 搜索问题的求解

- 解决一个搜索问题就是确定从开始状态到一个结束状态的动作序列，也被称为规划

#### 1.4.2 搜索算法的标准设定

- 过程
  - 搜索开始：从搜索树的根节点开始
  - 节点扩展：访问一个未被访问的但已经被发现的节点
  - 节点生成：发现新的节点
  - 目标测试：判断当前接待你对应的状态是否是目标状态
- 实现模块
  - 搜索边缘：已经生成但是未被访问的节点集合（fringe）
  - 节点扩展：访问一个节点，并枚举它所有邻居节点
  - 节点生成：将新节点加入到搜索边缘

> 注意：**生成 = 发现， 访问 = 扩展**

#### 1.4.3 搜索算法的评价

- 搜索树中的一些符号 ![alt text](image-6.png)
  - b 表示分支因子，树能到达的宽度
  - m 表示最大搜索高度/深度
  - s 目标状态对应的节点（可以为多个）
- 搜索树中的总节点个数：$1+b+b^2+...+b^m = \frac{1-b^{m+1}}{1-b} = O(b^m)$
- 评价搜索算法的四个指标
  - 完备性：如果存在目标节点，是否可以保证搜索到？
  - 最优性：最先找到的目标节点是不是损耗最小的？（如先找到更浅层的目标节点，而不是深的）
  - 时间复杂度：生成的节点个数（如果算法要生成所有的节点，那它的时间复杂度就是 $O(b^m)$
  - 空间复杂度：需要的存储空空间（搜索边缘的大小），即要保存找到的但未访问的节点的空间大小

### 1.5 树搜索和图搜索

#### 1.5.1 树搜索：额外的损耗

- 树搜索无法发现树中的重复结构，因此会产生额外的损耗（多对一的关系）
![alt text](image-7.png)
- 树搜索的改进：例子，对红色标记的 e 节点，我们不需要对第三层的 e 节点进行二次访问，因为第二层中已经可以访问 e 节点了，我们为了减少损耗会希望在第二层访问 e 节点
![alt text](image-8.png)

#### 1.5.2 图搜索

- 思路：同一个状态相关的节点不进行重复访问（一对一的关系）
- 实现：树搜索 + 保存访问过的节点集合（“已搜索集合”）
- 更新：每次扩展完一个节点，都更新“已搜索集合”
- 使用：在扩展一个节点之前，检查“已搜索集合”；如果该节点被包含，则跳过对它的扩展

#### 1.5.3 搜索算法的框架（伪代码）

![alt text](image-9.png)

### 1.6 代价无关搜索算法

#### 1.6.1 深度优先搜索（Depth-First Search, DFS）

- 搜索边缘：保存已经生成但是未被访问（扩展）节点的数据结构
- 扩展：从搜索边缘中选择一个节点进行扩展，获得它的所有邻居节点
- 生成：将一个新的节点插入到搜索边缘中
- 搜索策略：选择边缘中深度最大的节点进行扩展（距离根节点步数最多，如层数是 2 则深度为 2）
- 实现：搜索边缘可以使用后进先出的堆栈来实现

#### 1.6.2 深度优先搜索 - 演示

![alt text](image-10.png)

|边缘[~~扩展~~] stack|生成|已探索 set|
|--|--|--|
|~~S~~|p e d|S|
|p e ~~d~~|b c e|S d|
|p e ~~b~~ c e|a|S d b|
|p e ~~a~~ c e| |S d b a|
|p e ~~c~~ e|**a**|S d b **a** c|
|p e ~~e~~|r h|S d b a c e|
|...|...|...|

#### 1.6.3 深度优先搜索（DFS）的性质

![alt text](image-6.png)

- DFS 生成的节点个数（**时间复杂度**）？
  - 由于每次都是向更深的地方搜寻，因此可能要把整棵树都遍历完才会找到目标节点
  - 如果最大树高 m 是有限的，则为 $O(b^m)$
- DFS 需要的搜索边缘的大小（**空间复杂度**）？
  - 每层需要存储 b 个节点，一共 m 层，则为 $O(bm)$
- DFS 是完备的吗？
  - 不，树高 m 可能是无限的，DFS 可能向着一个无限的树高不停深挖，而无法找到另一个枝条的浅层的解
- DFS 是最优的吗？
  - 不，它会找到“最左边”的解，不管这个解的树高是多少

#### 1.6.4 广度优先搜索（Breadth-First Search, BFS）

- 搜索边缘：保存已经生成但是未被访问（扩展）节点的数据结构
- 扩展：从搜索边缘中选择一个节点进行扩展，获得它的所有邻居节点
- 生成：将一个新的节点插入到搜索边缘中
- 搜索策略：选择边缘中深度最小的节点进行扩展（距离根节点步数最少）
- 实现：搜索边缘可以使用先进先出的队列
![alt text](image-11.png)

#### 1.6.5 广度优先搜索（BFS）的性质

![alt text](image-12.png)

- BFS 生成的节点个数（**时间复杂度**）？
  - 假设树高最小的目标节点在 s 层，需要扩展所有树高大于等于 s 的节点
  - 需要生成的节点个数的复杂度为：$O(b^{s+1})$
  - 为什么是 s+1？因为当找到目标 s 层的时候，它的下一层已经被发现了，所以需要加一层
- BFS 需要的搜索边缘的大小（**空间复杂度**）？
  - 边缘需要保存生成的最后一层的所有节点，即$O(b^{s+1})$
- BFS 是完备的吗？
  - 是
- BFS 是最优的吗？
  - 是（如果每一步的损耗都是一样的）

#### 1.6.6 深度优先（DFS） vs 广度优先（BFS）

- 深度优先的空间复杂度更小
- 广度优先算法的时间复杂度更小，而且更健壮（完备且最优）

#### 1.6.7 迭代加深算法（Iterative Deepening Search, IDS）

- 结合深度优先的空间复杂度优势和广度优先的时间复杂度优势
  - 设定最大搜索深度为1，运行深度优先搜索算法，未发现目标
  - 设定最大搜索深度为2，运行深度优先搜索算法，未发现目标
  - 设定最大搜索深度为3，……
- IDS 生成的节点个数（时间复杂度）？
  - $O(b^s)$
- IDS 需要的搜索边缘的大小（空间复杂度）？
  - $O(bs)$
- 虽然 IDS 和 BFS 的时间复杂度相同，但 IDS 会生成更多的节点
  - $b+(b+b^2)+(b+b^2+b^3) = sb^1+(s-1)b^2+(s-2)b^3+...+b^{s+1} = O(sb^1+(s-1)b^2+(s-2)b^3+...+b^{s+1}) = O(b^{s+1})$

### 1.7 一致代价搜索算法

#### 1.7.1 代价敏感的搜索

- 广度优先搜索可以找到步数最短的搜索路径，但是它假设每一步的代价一样，因此不能保证路径的代价最小
- 接下来我们考虑每一步有不同代价，并学习代价敏感的搜索算法

![alt text](image-13.png)

#### 1.7.2 一致代价搜索（Uniform Cost Search, UCS）

- 搜索边缘：保存已经生成但是未被访问（扩展）节点的数据结构
- 扩展：从搜索边缘中选择一个节点进行扩展，获得它的所有邻居节点
- 生成：将一个新的节点插入到搜索边缘中
- 搜索策略：选择边缘中代价最小的节点（从根节点到当前节点的累积代价）
- 实现：搜索边缘可以使用优先队列

#### 1.7.3 一致代价搜索的执行过程

![alt text](image-15.png)

#### 1.7.4 一致代价搜索（UCS）的性质

![alt text](image-16.png)

>- C*：最优节点的累积代价
>- ε：搜索树中的最小单步代价
>- C* / ε：有效树高，从根节点到最优目标节点的最大步数

- 时间复杂度：$O(b^{C^* / (ε+1)})$
- 空间复杂度：$O(b^{C^* / (ε+1)})$
- 完备性：是，只要满足以下条件
  - （1）最优目标节点的代价是有限的
  - （2）最小单步代价是非负的
- 最优性：是，只要最小单步代价是非负的

#### 1.7.5 一致代价搜索（UCS）的其它性质

- UCS 遵循代价增加进行节点的依次访问
- 优点：UCS 是完备的和最优的
- 缺点：UCS 不考虑任何目标节点的额外性质，无差别地增加搜索半径

### 1.8 搜索算法对比

|算法|完备性|最优性|时间复杂度|空间复杂度|备注|
|--|--|--|--|--|--|
|DFS|N|N|$O(b^m)$|$O(bm)$|空间复杂度最好，时间复杂度最差；可能出现循环而无解|
|BFS|Y|Y|$O(b^{s+1})$|$O(b^{s+1})$|空间复杂度上需要保存下一层的节点，时间复杂度上也是；不会因为循环而无解|
|IDS|Y|Y|$O(b^s)$|$O(bs)$|结合 DFS 和 BFS 的优势|
|UCS|Y|Y|$O(b^{C^* / (ε+1)})$|$O(b^{C^* / (ε+1)})$|需要引入一个近似有效树高|

- b：分支因子
- s：最优目标节点的树高
- m：搜索树的最大深度
- C*：最优目标节点的累积代价
- ε：搜索树中的最小单步代价

 **假设分支因子和搜索树的最大树高是有限的，单步代价是非负的。**

> 例题：对于有限状态图上的搜索问题，以下说法正确的有（）。
>
> - [x] 深度优先图搜索（DFS）可以保证找到解（如果存在至少一解）
> - [x] 一致代价搜索（UCS）不一定总能找到最优解
> - [x] 存在广度优先树搜索有解而深度优先树搜索无解的案例
> - [ ] 存在深度优先树搜索有解而广度优先树搜索无解的案例

## 二、有信息搜索

### 2.1 启发式函数

#### 2.1.1 有信息搜索

- 在无信息的搜索中，我们只关心过去信息
  - 即：考虑从开始状态到当前节点的损耗（UCS 搜索中的成本），而忽略对于未来损耗的估计
- 在实际应用中，我们往往对搜索树中的节点有一些额外的信息

#### 2.1.2 启发式函数

- 用来估计当前状态离目标状态距离的函数
- 函数一般是为特定的搜索问题而设计的，即问题相关的
- 例如：曼哈顿距离、欧几里得距离，吃豆人为例，要得到小黄人去往豆子的距离 ![alt text](image-17.png)
- 用启发式函数可以加速我们的搜索

### 2.2 贪心搜索算法

#### 2.2.1 贪心搜索算法

- 搜索边缘：保存已经生成但是未被访问（扩展）节点的数据结构
- 扩展：从搜索边缘中选择一个节点进行扩展，获得它的所有邻居节点
- 生成：将一个新的节点插入到搜索边缘中
- 搜索策略：选择边缘中启发式函数值最小的节点（离目标“最近”的节点）
- 实现：搜索边缘使用优先队列实现

#### 2.2.2 贪心搜索 - 罗马尼亚旅游

![alt text](image-18.png)

- 看节点到目标城市的直线距离，选择直线距离最短的走
- 已访问的节点也会进入后续的计算和比较
- 最终和目标函数的启发式函数为 0，找到终点

#### 2.2.3 贪心搜索 - 什么时候出错？

![alt text](image-19.png)

- 从 Lasi 到 Fagaras 
- 最优解：I → V → U → B → F
- 贪心解：I → N → I → N → I ...... 无限循环
- 缺点：贪婪搜索不关心历史损耗

#### 2.2.4 贪心搜索的性质

- 策略：扩展看上去最接近目标状态的节点（最小的启发式函数值）
- 启发式函数：到最近目标的距离
- “最佳优先”会让你直奔目标（可能是错误的） ![alt text](image-20.png)
- 不是完备的，可能让你陷入无穷循环的困境中
- 不是最优的

### 2.3 A 搜索算法

#### 2.3.1 A*搜索

- 历史：从起始节点到当前节点的成本
- 未来：从当前节点到目标节点的估计
- A* 同时考虑历史和未来两个维度的信息

- 估值函数 f(n)
  - f(n) = g(n) + h(n)
  - g(n)：从开始节点到当前节点的损耗
  - h(n)：当前节点到目标节点损耗的启发式估计

#### 2.3.2 示例：一致代价搜索 vs 贪心搜索 vs A*

![alt text](image-21.png)

- 写出每个算法选择的搜索路径，S 为起点，G 为终点
  - 假设：g(S) = 0, (G) = 0
- 一致代价：按历史路径的成本 g(n) 做节点访问的优先级排序
- 贪心搜索：按目标接近度或远期成本 b(n) 做节点访问的优先级排序
- A*搜索：结合历史损耗和未来估计 f(n) = g(n) + h(n) 进行排序

![alt text](image-22.png)

|算法|结果路径|扩展的节点|
|--|--|--|
|最优|S → a → d → G|S, a, d, G|
|一致代价|S → a → d → G|S, a, b, c, d, G|
|贪心|S → a → e → d → G|S, a, e, d, G|
|A*|S → a → d → G|S, a, d, G|

#### 2.3.3 A*是最优的吗？

![alt text](image-23.png)

- 我们需要在 G 之前从搜索边缘弹出节点 A 以得到最优解
- F(A) < F(G) → h(A) + g(A) < g(G) + h(G) → **h(A) < g(G) - g(A)**
- **节点的估计应小于节点到目标的实际损耗，才能找到最优的节点 A**

### 2.4 可采纳的启发式函数

#### 2.4.1 



#### 2.4.2 




#### 2.4.3 



### 2.5 一致的启发式函数

#### 2.5.1




#### 2.5.2




#### 2.5.3




### 2.6 构建启发式函数






### 2.7 启发式函数的性质






## 三、对抗搜索




## 四、约束满足问题




## 五、强化学习 - 有模型的方法




## 六、强化学习 - 无模型的方法


## 七、强化学习 - 值函数近似的方法





## 八、概率图模型 - 表示




## 八、概率图模型 - 推理



## 八、概率图模型 - 隐马尔可夫模型




## 九、强化学习模块



## 十、搜索算法模块